{
  "plenaries": [
    {
      "id": "two-paths-to-intelligence",
      "title": "Two Paths to Intelligence",
      "desc": "Keynote: Geoffrey Hinton\nCohere\n\nMonday, July 10 - Time: 09:30\u201310:30 EDT\n\nAbstract: I will briefly describe the forty year history of neural net\nlanguage models with particular attention to whether they understand\nwhat they are saying. I will then discuss some of the main differences\nbetween digital and biological intelligences and speculate on how the\nbrain could implement something like transformers. I will conclude by\naddressing the contentious issue of whether current multimodal LLMs have\nsubjective experience.\n",
      "location": "Metropolitan",
      "start_time": "2023-07-10T09:30:00",
      "end_time": "2023-07-10T10:30:00",
      "bio": " Geoffrey Hinton received his PhD in Artificial Intelligence from\nEdinburgh in 1978. After five years as a faculty member at\nCarnegie-Mellon he became a fellow of the Canadian Institute for\nAdvanced Research and moved to the University of Toronto where he is now\nan emeritus professor. He is also the Chief Scientific Adviser at the\nVector Institute.\n\nHe was one of the researchers who introduced the backpropagation\nalgorithm and the first to use backpropagation for learning word\nembeddings. His other contributions to neural network research include\nBoltzmann machines, distributed representations, time-delay neural nets,\nmixtures of experts, variational learning and deep learning. His\nresearch group in Toronto made major breakthroughs in deep learning that\nrevolutionized speech recognition and object classification.\n\nHe is a fellow of the UK Royal Society and a foreign member of the US\nNational Academy of Engineering, the US National Academy of Sciences and\nthe American Academy of Arts and Sciences. His awards include the David\nE. Rumelhart prize, the IJCAI award for research excellence, the Killam\nprize for Engineering, the Royal Society Royal Medal, the NSERC Herzberg\nGold Medal, the IEEE James Clerk Maxwell Gold medal, the NEC C&C award,\nthe BBVA award, the Honda Prize and the Turing Award.\n",
      "speaker_name": "Geoffrey Hinton",
      "institution": "University of Toronto (emeritus)",
      "image": "invited1.jpg"
    },
    {
      "id": "large-language-models-as-cultural-technologies_-imitation-and-innovation-in-children-and-models",
      "title": "Large Language Models as Cultural Technologies: Imitation and Innovation in Children and Models",
      "desc": "Alison Gopnik\nUniversity of California, Berkeley\n\nWednesday, July 12 - Time: 14:00\u201315:00 EDT\n\nAbstract: Its natural to ask whether large language models like LaMDA or\nGPT-3 are intelligent agents. But I argue that this is the wrong\nquestion. Intelligence and agency are the wrong categories for\nunderstanding them. Instead, these Al systems are what we might call\ncultural technologies, like writing, print, libraries, internet search\nengines or even language itself. They are new techniques for passing on\ninformation from one group of people to another. Cultural technologies\narent like intelligent humans, but they are essential for human\nintelligence. Many animals can transmit some information from one\nindividual or one generation to another, but no animal does it as much\nas we do or accumulates as much information over time, . New\ntechnologies that make cultural transmission easier and more effective\nhave been among the greatest engines of human progress, but they have\nalso led to negative as well as positive social consequences. Moreover,\nwhile cultural technologies allow transmission of existing information\ncultural evolution, which is central to human success, also depends on\ninnovation, exploration and causal learning. Comparing LLM\u2019s responses\nin prompts based on developmental psychology experiments to the\nresponses of children may provide insight into which capacities can be\nlearned through language and cultural transmission, and which require\ninnovation and exploration in the physical world. I will present results\nfrom several studies making such comparisons.\n",
      "location": "Metropolitan",
      "start_time": "2023-07-12T14:00:00",
      "end_time": "2023-07-12T15:00:00",
      "bio": " Alison Gopnik is a professor of psychology and affiliate professor\nof philosophy at the University of California at Berkeley, and a member\nof the Berkeley AI Research Group. She received her BA from McGill\nUniversity and her PhD. from Oxford University. She is a leader in the\nstudy of cognitive science and of children\u2019s learning and development\nand was one of the founders of the field of \u201ctheory of mind\u201d, an\noriginator of the \u201ctheory of cognitive development\u201d, and the first to\napply Bayesian probabilistic models to children\u2019s learning. She has\nreceived both the APS Lifetime Achievement Cattell and William James\nAwards, the Bradford Washburn Award for Science Communication, and the\nSRCD Lifetime Achievement Award for Basic Science in Child Development.\nShe is an elected member of the Society of Experimental Psychologists\nand the American Academy of Arts and Sciences and a Cognitive Science\nSociety, American Association for the Advancement of Science, and\nGuggenheim Fellow. She was 2022-23 President of the Association for\nPsychological Science.\n\nShe is the author or coauthor of over 140 journal articles and several\nbooks including \u201cWords, thoughts and theories\u201d MIT Press, 1997, and the\nbestselling and critically acclaimed popular books \u201cThe Scientist in the\nCrib\u201d William Morrow, 1999, \u201cThe Philosophical Baby; What children\u2019s\nminds tell us about love, truth and the meaning of life\u201d 2009, and \u201cThe\nGardener and the Carpenter\u201d 2016, Farrar, Strauss and Giroux, the latter\ntwo won the Cognitive Development Society Best Book Prize in 2009 and\n2016. Since 2013 she has written the Mind and Matter column for the Wall\nStreet Journal and she has also written widely about cognitive science\nand psychology for The New York Times, The Economist, The Atlantic, The\nNew Yorker, Scientific American, The Times Literary Supplement, The New\nYork Review of Books, New Scientist and Slate, among others. Her TED\ntalk on her work has been viewed more than 5.2 million times. She has\nfrequently appeared on TV, radio and podcasts including \u201cThe Charlie\nRose Show\u201d, \u201cThe Colbert Report\u201d, \u201cRadio Lab\u201d and \u201cThe Ezra Klein Show\u201d.\nShe lives in Berkeley with her husband Alvy Ray Smith and has three\nchildren and five grandchildren.\n",
      "speaker_name": "Alison Gopnik",
      "institution": "University of California at Berkeley",
      "image": "invited2.jpg"
    },
    {
      "id": "the-future-of-computational-linguistics-in-the-llm-age",
      "title": "The Future of Computational Linguistics in the LLM Age",
      "desc": "Chair: Iryna Gurevych\nTechnische Universit\u00e4t Darmstadt\n\nTuesday, July 11 - Time: 14:45-15:45\n\nThis is a panel discussion with:\n\n-   Dan Klein (UC Berkeley)\n\n-   Meg Mitchell (Hugging Face)\n\n-   Roy Schwartz (the Hebrew University of Jerusalem)\n\nThey will present short statements (5 to 7 min.) related to the main\ntopic of the panel\n\n-   New opportunities (e.g., artificial general intelligence,\n    responsible NLP);\n\n-   Technical challenges (e.g., multimodality, instruction-tuning, etc.)\n\n-   Real life problems & societal implications (e.g., hallucinations,\n    biases, future job market);\n\n-   LLMs and the future of NLP; and\n\n-   Open-science vs. commercial LLMs\n\nFollowed by discussion with the panel and audience.\n",
      "location": "Metropolitan",
      "start_time": "2023-07-11T14:45:00",
      "end_time": "2023-07-11T15:45:00",
      "bio": "",
      "speaker_name": "Dan Klein (UC Berkeley), Meg Mitchell (Hugging Face), Roy Schwartz (Hebrew University of Jerusalem)",
      "institution": null,
      "image": null
    },
    {
      "id": "memorial",
      "title": "Memorial",
      "desc": "[image]\n\nTuesday, July 11, 2023 - Room: Metropolitan - Time: 13:00\u201313:30\n\nDragomir Radev, the A. Bartlett Giamatti Professor of Computer Science\nat Yale University, passed away this year on Wed, March 29th. Drago\ncontributed in substantial ways to research in NLP, to the organization\nof the ACL and to mentoring the next generation of computational\nlinguists. Drago\u2019s role in our ACL community spans four decades. He was\nrecognized for his work over this period through his selection as an ACL\nFellow in 2018 for his significant contributions to text summarization\nand question answering, and through his receipt of the Distinguished ACL\nService Award in 2022. In this session, speakers from different time\nperiods of his life will discuss his contributions to the field and the\nimpact his life had on so many of us.\n",
      "location": "Metropolitan",
      "start_time": "2023-07-11T13:00:00",
      "end_time": "2023-07-11T13:30:00",
      "bio": "",
      "speaker_name": null,
      "institution": null,
      "image": "drago.jpg"
    },
    {
      "id": "acl-rolling-review-update-and-discussion",
      "title": "ACL Rolling Review Update and Discussion",
      "desc": "Mausam, Professor, IIT Delhi (ARR EIC), Jonathan K. Kummerfeld,\nAssistant Professor, University of Sydney (ARR CTO)\nTuesday, July 11, 2023 - Room: Metropolitan - Time: 14:15\u201314:45\n\nThis session will contain a presentation on progress in ARR over the\npast year and provide an opportunity for community questions and\ndiscussion.\n\nWe will briefly present:\n\nPersonnel Updates New aspects: Tracks, Senior Action Editors\nImprovements, e.g. changes to the review - paper matching process\nStatistics on timeliness and paper outcomes Next steps\n\nWith that context we will open the floor to questions.\n",
      "location": "Metropolitan",
      "start_time": "2023-07-11T14:15:00",
      "end_time": "2023-07-11T14:45:00",
      "bio": "",
      "speaker_name": null,
      "institution": null,
      "image": null
    },
    {
      "id": "ethics-panel",
      "title": "Ethics Panel",
      "desc": "Kar\u00ebn Fort, Min-Yen Kan and Yulia Tsvetkov (ACL Ethics Committee\nco-chairs) Committee Members: Luciana Benotti, Mark Dredze, Pascale\nFung, Dirk Hovy, Jin-Dong Kim, Malvina Nissim\nTuesday, July 11, 2023 - Room: Pier 4&5 - Time: 16:15\u201317:45\n\nWe present our ACL Ethics Committee\u2019s progress over the last few years.\nOf core interest, we will present the results of the ACL stakeholder\nsurvey about the role of ethics and ethics training exposure. Results\nfrom the survey respondents indicate that ethics is of primary interest\nto the community and that there is a mandate for the further creation\nand dissemination of ethics related training for authors, reviewers and\nevent organisers. We will briefly review the survey results and feature\na lengthed question and answer session in support of extended dialogue\nwith our community. Our session will culminate through a dialogue with\nour session\u2019s participants in a moderated panel that includes\nparticipation from the entire ethics committee.\n",
      "location": "Pier 4\\&5",
      "start_time": "2023-07-11T16:15:00",
      "end_time": "2023-07-11T17:45:00",
      "bio": "",
      "speaker_name": null,
      "institution": null,
      "image": null
    },
    {
      "id": "navigating-nlp-in-the-era-of-llm",
      "title": "Navigating NLP in the Era of Large Language Models",
      "desc": "Join us for a panel featuring experts Sara Hooker (Cohere), Swaroop Mishra (Google DeepMind), and Danqi Chen (Princeton), who will provide invaluable insights into navigating the tempestuous seas of NLP in the era of large language models. This discussion will guide students and early career researchers through impactful directions, progress-making strategies, offering perspectives from academia and industry.\n\nTuesday, July 11 - Time: 13:45â€“14:30 EDT\n\nRoom: Pier 2&3",
      "location": "Pier 2\\&3",
      "start_time": "2023-07-11T13:45:00",
      "end_time": "2023-07-11T14:30:00",
      "bio": "",
      "speaker_name": "Danqi Chen (Princeton), Swaroop Mishra (Google DeepMind) and Sara Hooker (Cohere)",
      "institution": null,
      "image": null
    }
  ],
  "tutorials": [
    {
      "id": "t1",
      "title": "T1: Goal Awareness for Conversational AI: Proactivity, Non-collaborativity, and Beyond",
      "desc": "Conversational systems are envisioned to provide social support or functional service to human users via natural language interactions. Conventional conversation researches mainly focus on the responseability of the system, such as dialogue context understanding and response generation, but overlooks the design of an essential property in intelligent conversations, i.e., goal awareness. The awareness of goals means the state of not only being responsive to the users but also aware of the target conversational goal and capable of leading the conversation towards the goal, which is a significant step towards higher-level intelligence and artificial consciousness. It can not only largely improve user engagement and service efficiency in the conversation, but also empower the system to handle more complicated conversation tasks that involve strategical and motivational interactions. In this tutorial, we will introduce the recent advances on the design of agent's awareness of goals in a wide range of conversational systems.",
      "location": "Metropolitan East",
      "start_time": "2023-07-09T09:00:00",
      "end_time": "2023-07-09T12:30:00",
      "hosts": [
        "Minlie Huang",
        "Tat-Seng Chua",
        "Wenqiang Lei",
        "Yang Deng"
      ],
      "rocketchat": "tutorial-1"
    },
    {
      "id": "t2",
      "title": "T2: Complex Reasoning in Natural Language",
      "desc": "Teaching machines to reason over texts has been a long-standing goal of natural language processing (NLP). To this end, researchers have designed a diverse set of complex reasoning tasks that involve compositional reasoning, knowledge retrieval, grounding, commonsense reasoning, etc.A standard choice for building systems that perform a desired type of reasoning is to fine-tune a pretrained language model (LM) on specific downstream tasks. However, recent research has demonstrated that such a straightforward approach is often brittle. For example, Elazar et al. (2021) and Branco et al. (2021) show that, on question-answering (QA) tasks, similar performance can be achieved with questions removed from the inputs. Min et al. (2019), Chen and Durrett (2019), and Tang et al. (2021) show that models trained on multi-hop QA do not generalize to answer single-hop questions. The reasoning capabilities of these models thus remain at a surface level, i.e., exploiting data patterns. Consequently, augmenting LMs with techniques that make them robust and effective becomes an active research area.We will start the tutorial by providing an overview of complex reasoning tasks where the standard application of pretrained language models fails. This tutorial then reviews recent promising directions for tackling these tasks. Specifically, we focus on the following groups of approaches that explicitly consider problem structures: (1) knowledge-augmented methods, where the knowledge is either incorporated during fine-tuning or pretraining; (2) few-shot prompting methods, which effectively guide the models to follow instructions; (3) neuro-symbolic methods, which produce explicit intermediate representations; and, (4) rationale-based methods, one of the most popular forms of the neuro-symbolic methods, which highlight subsets of input as explanations for individual model predictions.",
      "location": "Metropolitan Centre",
      "start_time": "2023-07-09T09:00:00",
      "end_time": "2023-07-09T12:30:00",
      "hosts": [
        "Aman Madaan",
        "Bill Yuchen Lin",
        "Michihiro Yasunaga",
        "Mor Geva",
        "Tao Yu",
        "Wenting Zhao"
      ],
      "rocketchat": "tutorial-2"
    },
    {
      "id": "t3",
      "title": "T3: Everything you need to know about Multilingual LLMs: Towards fair, performant and reliable models for languages of the world",
      "desc": "This tutorial will describe various aspects of scaling up language technologies to many of the world's languages by describing the latest research in Massively Multilingual Language Models (MMLMs). We will cover topics such as data collection, training and fine-tuning of models, Responsible AI issues such as fairness, bias and toxicity, linguistic diversity and evaluation in the context of MMLMs, specifically focusing on issues in non-English and low-resource languages. Further, we will also talk about some of the real-world challenges in deploying these models in language communities in the field. With the performance of MMLMs improving in the zero-shot setting for many languages, it is now becoming feasible to use them for building language technologies in many languages of the world, and this tutorial will provide the computational linguistics community with unique insights from the latest research in multilingual models",
      "location": "Metropolitan West",
      "start_time": "2023-07-09T09:00:00",
      "end_time": "2023-07-09T12:30:00",
      "hosts": [
        "Barun Patra",
        "Kabir Ahuja",
        "Kalika Balia",
        "Monojit Choudhury",
        "Sunayana Sitaram",
        "Vishrav Chaudhary"
      ],
      "rocketchat": "tutorial-3"
    },
    {
      "id": "t4",
      "title": "T4: Generating Text from Language Models",
      "desc": "An increasingly large percentage of natural language processing (NLP) tasks center around the generation of text from probabilistic language models. Despite this trend, techniques for improving or specifying preferences in these generated texts rely mostly on intuition-based heuristics. Further, there lacks a unified presentation of their motivations, practical implementation, successes and pitfalls. Practitioners must, therefore, choose somewhat blindly between generation algorithms---like top-p sampling or beam search---which can lead to wildly different results. At the same time, language generation research continues to criticize and improve the standard toolboxes, further adding entropy to the state of the field. In this tutorial, we will provide a centralized and cohesive discussion of critical considerations when choosing how to generate from a language model. We will cover a wide range of empirically-observed problems (like degradation, hallucination, repetition) and their corresponding proposed algorithmic solutions from recent research (like top-p sampling and its successors). We will then discuss a subset of these algorithms under a unified light; most stochastic generation strategies can be framed as locally adapting the probabilities of a model to avoid failure cases. Finally, we will then cover methods in controlled generation, that go beyond just ensuring coherence to ensure text exhibits specific desired properties. We aim for NLP practitioners and researchers to leave our tutorial with a unified framework which they can use to evaluate and contribute to the latest research in language generation.",
      "location": "Metropolitan East",
      "start_time": "2023-07-09T14:00:00",
      "end_time": "2023-07-09T17:30:00",
      "hosts": [
        "Afra Amini",
        "Clara Meister",
        "John Hewitt",
        "Ryan Cotterell",
        "Tiago Pimentel"
      ],
      "rocketchat": "tutorial-4"
    },
    {
      "id": "t5",
      "title": "T5: Indirectly Supervised Natural Language Processing",
      "desc": "This tutorial targets researchers and practitioners who are interested in ML technologies for NLP from indirect supervision. In particular, we will present a diverse thread of indirect supervision studies that try to answer the following questions: (i) when and how can we provide supervision for a target task T, if all we have is data that corresponds to a related task T? (ii) humans do not use exhaustive supervision; they rely on occasional feedback, and learn from incidental signals from various sources; how can we effectively incorporate such supervision in machine learning? (iii) how can we leverage multi-modal supervision to help NLP? To the end, we will discuss several lines of research that address those challenges, including (i) indirect supervision from T' that handles T with outputs spanning from a moderate size to an open space, (ii) the use of sparsely occurring and incidental signals, such as partial labels, noisy labels, knowledge-based constraints, and cross-domain or cross-task annotations\u2014all having statistical associations with the task, (iii) principled ways to measure and understand why these incidental signals can contribute to our target tasks, and (iv) indirect supervision from vision-language signals. We will conclude the tutorial by outlining directions for further investigation.",
      "location": "Metropolitan Centre",
      "start_time": "2023-07-09T14:00:00",
      "end_time": "2023-07-09T17:30:00",
      "hosts": [
        "Ben Zhou",
        "Dan Roth",
        "Kai-Wei Chang",
        "Muhao Chen",
        "Qiang Ning",
        "Wenpeng Yin"
      ],
      "rocketchat": "tutorial-5"
    },
    {
      "id": "t6",
      "title": "T6: Retrieval-based Language Models and Applications",
      "desc": "Retrieval-based language models (LMs) have shown impressive performance on diverse NLP tasks. In this tutorial, we will provide a comprehensive and coherent overview of recent advances in retrieval-based LMs. We will start by providing preliminaries covering the foundation of LMs (e.g., masked LMs, autoregressive LMs) and retrieval systems (e.g., nearest-neighbor search). We will then detail recent progress in retrieval-based models, focusing on their model architectures and learning approaches. Finally, we will show how retrieval-based LMs are adapted to downstream applications, and extended to multilingual and multi-modal settings. Finally, we will use an exercise to showcase the effectiveness of retrieval-based LMs.",
      "location": "Metropolitan West",
      "start_time": "2023-07-09T14:00:00",
      "end_time": "2023-07-09T17:30:00",
      "hosts": [
        "Akari Asai",
        "Danqi Chen",
        "Sewon Min",
        "Zexuan Zhong"
      ],
      "rocketchat": "tutorial-6"
    }
  ],
  "workshops": [
    {
      "id": "workshop_1",
      "title": "W1 - The 17th International Workshop on Semantic Evaluation (SemEval)",
      "desc": "The 17th edition of SemEval features 12 TASKS on a range of topics, including tasks on idiomaticy detection and embedding, sarcasm detection, multilingual news similarity, and linking mathematical symbols to their descriptions. Several tasks are multilingual, and others ask for multimodal approaches.",
      "location": "Queens Quay",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://semeval.github.io/SemEval2023/",
      "chair": "Ritesh Kumar, Atul Kr. Ojha, A. Seza Do\u011fru\u00f6z, Giovanni Da San Martino, Harish Tayyar Madabushi"
    },
    {
      "id": "workshop_2",
      "title": "W2 - The 12th Joint Conference on Lexical and Computational Semantics (*SEM)",
      "desc": "The 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023) is organized and sponsored by SIGLEX, the Special Interest Group of the ACL. *SEM brings together researchers interested in the semantics of natural languages and its computational modeling. The conference embraces data-driven, neural, and probabilistic approaches, as well as symbolic approaches and everything in between; practical applications as well as theoretical contributions are welcome. The long-term goal of *SEM is to provide a stable forum for the growing number of NLP researchers working on all aspects of semantics of (many and diverse!) natural languages.",
      "location": "Pier 5",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://sites.google.com/view/starsem2023",
      "chair": "Mohammad Taher Pilehvar, Jose Camacho-Collados, Alexis Palmer, Malihe Alikhani, Mert Inan"
    },
    {
      "id": "workshop_3",
      "title": "W3 - The 4th Workshop on Computational Approaches to Discourse (CODI)",
      "desc": "The last ten years have seen a dramatic improvement in the ability of NLP systems to understand and produce words and sentences. This development has created a renewed interest in discourse phenomena as researchers move towards the processing of long-form text and conversations. There is a surge of activity in discourse parsing, coherence models, text summarization, corpora for discourse level reading comprehension, and discourse related/aided representation learning, to name a few, but the problems in computational approaches to discourse are still substantial. At this juncture, we have organized three Workshops on Computational Approaches to Discourse (CODI) at EMNLP 2020, EMNLP 2021 and COLING 2022 to bring together discourse experts and upcoming researchers. These workshops have catalyzed work to improve the speed and knowledge needed to solve such problems and have served as a forum for the discussion of suitable datasets and reliable evaluation methods.",
      "location": "Pier 9",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://sites.google.com/view/codi-2023/",
      "chair": "Chlo\u00e9 Braud, Christian Hardmeier, Junyi Jessy Li, Sharid Lo\u00e1iciga, Michael Strube, Amir Zeldes"
    },
    {
      "id": "workshop_4",
      "title": "W4 - The 20th International Conference on Spoken Language Translation (IWSLT)",
      "desc": "The International Conference on Spoken Language Translation (IWSLT) is an annual scientific conference, associated with an open evaluation campaign on spoken language translation, where both scientific papers and system descriptions are presented.",
      "location": "Dockside 1",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://iwslt.org/2023/",
      "chair": "Marine Carpuat, Marcello Federico, Alex Waibel, Jan Niehues, Sebastian St\u00fcker, Elizabeth Salesky, Atul Kr. Ojha"
    },
    {
      "id": "workshop_5",
      "title": "W5 - The 8th Workshop on Representation Learning for NLP (RepL4NLP)",
      "desc": "The 8th Workshop on Representation Learning for NLP aims to continue the success of the Repl4NLP workshop series, with the 1st Workshop on Representation Learning for NLP having received about 50 submissions and over 250 attendees - the second most attended collocated event at ACL'16 after WMT. The workshop was introduced as a synthesis of several years of independent *CL workshops focusing on vector space models of meaning, compositionality, and the application of deep neural networks and spectral methods to NLP. It provides a forum for discussing recent advances on these topics, as well as future research directions in linguistically motivated vector-based models in NLP. The workshop will take place in a hybrid setting, and, as in previous years, feature interdisciplinary keynotes, paper presentations, posters, as well as a panel discussion.",
      "location": "Harbour B",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://sites.google.com/view/repl4nlp2023",
      "chair": "Burcu Can, Maximilian Mozes, Samuel Cahyawijaya, Naomi Saphra, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Chen Zhao"
    },
    {
      "id": "workshop_6",
      "title": "W6 - The 4th Workshop on Simple and Efficient Natural Language Processing (SustaiNLP)",
      "desc": "The Natural Language Processing (NLP) community has, in recent years, demonstrated a notable focus on improving higher scores on standard benchmarks and taking the lead on community-wide leaderboards (e.g., GLUE, SentEval). While this aspiration has led to improvements in benchmark performance of (predominantly neural) models, it has also came at a cost, i.e., increased model complexity and the ever-growing amount of computational resources required for training and using the current state-of-the-art models. Moreover, the recent research efforts have, for the most part, failed to identify sources of empirical gains in models, often failing to empirically justify the model complexity beyond benchmark performance. \\newline Because of these easily observable trends, we have proposed the SustaiNLP workshop with the goal of promoting more sustainable NLP research and practices, with two main objectives: (1) encouraging development of more efficient NLP models; and (2) providing simpler architectures and empirical justification of model complexity. For both aspects, we will encourage submissions from all topical areas of NLP.",
      "location": "Harbour C",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://sites.google.com/view/sustainlp2023",
      "chair": "Nafise Sadat Moosavi, Iryna Gurevych, Yufang Hou, Gyuwan Kim, Young Jin Kim, Tal Schuster, Ameeta Agrawal"
    },
    {
      "id": "workshop_7",
      "title": "W7 - The 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA)",
      "desc": "The BEA Workshop is a leading venue for NLP innovation in the context of educational applications. It is one of the largest one-day workshops in the ACL community with over 100 registered attendees in the past several years. The growing interest in educational applications and a diverse community of researchers involved resulted in the creation of the Special Interest Group in Educational Applications (SIGEDU) in 2017, which currently has over 300 members.",
      "location": "Harbour A",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://sig-edu.org/bea/2023",
      "chair": "Ekaterina Kochmar, Jill Burstein, Andrea Horbach, Ronja Laarmann-Quante, Nitin Madnani, Ana\u00efs Tack, Victoria Yaneva, Zheng Yuan, Torsten Zesch"
    },
    {
      "id": "workshop_8",
      "title": "W8 - The 1st Workshop on Natural Language Reasoning and Structured Explanations",
      "desc": "With recent scaling of large pre-trained Transformer language models (LLMs), the scope of feasible NLP tasks has broadened. Significant recent work has focused on tasks that require some kind of natural language reasoning. A trajectory in question answering has led us from extraction-oriented datasets like SQuAD to \u201cmulti-hop\u201d reasoning datasets like HotpotQA and StrategyQA. Although LLMs have shown remarkable performance on most NLP tasks, it is often unclear why their answers follow from what they know. To address this gap, a new class of explanation techniques has emerged which play an integral part in structuring the reasoning necessary to solve these datasets. For example, the chain-of-thought paradigm leverages explanations as vehicles for LLMs to mimic human reasoning processes. Entailment trees offer a way to ground multi-step reasoning in a collection of verifiable steps. Frameworks like SayCan bridge high-level planning in language and with low-level action trajectories. As a result, we see a confluence of methods blending explainable machine learning/NLP, classical AI (especially theorem proving), and cognitive science (how do humans structure explanations?). This workshop aims to bring together a diverse set of perspectives from these different traditions and attempt to establish common ground for how these various kinds of explanation structures can tackle a broad class of reasoning problems in natural language and beyond.",
      "location": "Pier 4",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://nl-reasoning-workshop.github.io/",
      "chair": "Peter Clark, Ellie Pavlick, Denny Zhou, Noah Goodman, Sarah Wiegreffe, Felix Hill"
    },
    {
      "id": "workshop_9",
      "title": "W9 - The 7th Workshop on Online Abuse and Harms (WOAH)",
      "desc": "The goal of The Workshop on Online Abuse and Harms (WOAH) is to advance research that develops, interrogates and applies computational methods for detecting, classifying and modelling online abuse.",
      "location": "Pier 7 and 8",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://www.workshopononlineabuse.com/",
      "chair": "Yi-Ling Chung, Aida Mostafazadeh Davani, Debora Nozza, Paul R\u00f6ttger, Zeerak Talat"
    },
    {
      "id": "workshop_10",
      "title": "W10 - The 3rd Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc)",
      "desc": "The DialDoc workshop focuses on Document-Grounded Dialogue and Conversational Question Answering. Given the vast amount of content created every day in various mediums, it is a meaningful yet challenging task not only to make such content accessible to end users via various conversational interfaces, but also to make sure the responses provided by the models are grounded and faithful with respect to the knowledge sources.",
      "location": "Dockside 2",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://doc2dial.github.io/workshop2023/",
      "chair": "Roee Aharoni, Nouha Dziri, Song Feng, Yongbin Li, Yu Li, Hui Wan"
    },
    {
      "id": "workshop_11",
      "title": "W11 - The 1st Workshop on Matching From Unstructured and Structured Data (MATCHING)",
      "desc": "Matching Entities from structured and unstructured sources is an important task in many  domains and applications such as HR and E-commerce. For example, in HR platforms/services, it is important to match resumes to job descriptions and job seekers to companies. Similarly in web platforms/services, it is important to match customers to businesses such as hotels and restaurant, among others. In such domains, it is also relevant to match \u201ctextual customer reviews\u201d to customers queries, and sentences (or phrases) as answers to customer questions. Recent advances in Natural Language Processing, Natural Language Understanding, Conversational AI, Language Generation, Machine Learning, Deep Learning, Data Management, Information Extraction, Knowledge Bases/Graphs, (MultiSingle Hop/Commonsense) Inference/Reasoning, Recommendation Systems, and others, have demonstrated promising results in different Matching tasks related (but not limited) to the previously mentioned domains. We believe that there is tremendous opportunity to further exploit and explore the use of advanced NLP (and language related) techniques applied to Matching tasks. Therefore, the goal of this workshop is to bring together the research communities (from academia and industry) of these related areas, that are interested in the development and the application of novel natural-language-based approaches/models/systems to address challenges around different Matching tasks.",
      "location": "Dockside 3",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://megagon.ai/matching-2023/",
      "chair": "Dunia Mladeni\u0107, Estevam Hruschka, Marko Grobelnik, Sajjadur Rahman, Tom Mitchell"
    },
    {
      "id": "workshop_12",
      "title": "W12 - The 17th Workshop on Linguistic Annotation (LAW)",
      "desc": "Linguistic annotation of natural language corpora is the backbone of supervised methods of statistical natural language processing. The Linguistic Annotation Workshop (LAW) is the annual workshop of the ACL Special Interest Group on Annotation (SIGANN), and it provides a forum for the presentation and discussion of innovative research on all aspects of linguistic annotation, including the creation and evaluation of annotation schemes, methods for automatic and manual annotation, use and evaluation of annotation software and frameworks, representation of linguistic data and annotations, semi-supervised \u201chuman in the loop\u201d methods of annotation, crowd-sourcing approaches, and more. As in the past, the LAW will provide a forum for annotation researchers to work towards standardization, best practices, and interoperability of annotation information and software.",
      "location": "Pier 3",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://sigann.github.io/LAW-XVII-2023/",
      "chair": "Annemarie Friedrich, Jakob Prange, Amir Zeldes, Ines Rehbein"
    },
    {
      "id": "workshop_13",
      "title": "W13 - The 22nd Workshop on Biomedical Natural Language Processing and Shared Tasks (BioNLP-ST)",
      "desc": "The BioNLP workshop associated with the ACL SIGBIOMED special interest group has established itself as the primary venue for presenting foundational research in language processing for the biological and medical domains. The workshop is running every year since 2002 and continues getting stronger. BioNLP welcomes and encourages work on languages other than English, and inclusion and diversity. BioNLP truly encompasses the breadth of the domain and brings together researchers in bio- and clinical NLP from all over the world. The workshop will continue presenting work on a broad and interesting range of topics in NLP. The interest to biomedical language has broadened significantly due to the COVID-19 pandemic and continues to grow: as access to information becomes easier and more people generate and access health-related text, it becomes clearer that only language technologies can enable and support adequate use of the biomedical text.",
      "location": "Pier 2",
      "start_time": "2023-07-13T09:00:00",
      "end_time": null,
      "url": "https://aclweb.org/aclwiki/BioNLP_Workshop",
      "chair": "Kevin Bretonnel Cohen, Dina Demner-Fushman, Sophia Ananiadou, Jun-ichi Tsujii"
    },
    {
      "id": "workshop_14",
      "title": "W14 - The 5th Workshop on NLP for Conversational AI",
      "desc": "Over the past decades, mathematicians, linguists, and computer scientists have dedicated their efforts towards empowering human-machine communication in natural language. While in recent years the emergence of virtual personal assistants such as Siri, Alexa, Google Assistant, Cortana, and ChatGPT has pushed the field forward, they may still have numerous challenges. \\newline Following the success of the 4th NLP for Conversational AI workshop at ACL, The 5th NLP4ConvAI will be a one-day workshop, co-located with ACL 2023 in Toronto, Canada. The goal of this workshop is to bring together researchers and practitioners to discuss impactful research problems in this area, share findings from real-world applications, and generate ideas for future research directions. \\newline The workshop will include keynotes, posters, panel sessions, and a shared task. In keynote talks, senior technical leaders from industry and academia will share insights on the latest developments in the field. We would like to encourage researchers and students to share their prospects and latest discoveries. There will also be a panel discussion with noted conversational AI leaders focused on the state of the field, future directions, and open problems across academia and industry.",
      "location": "Harbour B",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://sites.google.com/view/5thnlp4convai/",
      "chair": "Abhinav Rastogi, Georgios Spithourakis, Yun-Nung (Vivian) Chen, Bing Liu, Yu Li, Elnaz Nouri, Alon Albalak, Alexandros Papangelis"
    },
    {
      "id": "workshop_15",
      "title": "W15 - The 3rd Workshop on Trustworthy NLP (TrustNLP)",
      "desc": "Recent advances in Natural Language Processing, and the emergence of pretrained Large Language Models (LLM) specifically, have made NLP systems omnipresent in various aspects of our everyday life. In addition to traditional examples such as personal voice assistants, recommender systems, etc, more recent developments include content-generation models such as ChatGPT, text-to-image models (Dall-E), and so on. While these emergent technologies have an unquestionable potential to power various innovative NLP and AI applications, they also pose a number of challenges in terms of their safe and ethical use. To address such challenges, NLP researchers have formulated various objectives, e.g., intended to make models more fair, safe, and privacy-preserving. However, these objectives are often considered separately, which is a major limitation since it is often important to understand the interplay and/or tension between them. For instance, meeting a fairness objective might require access to users\u2019 demographic information, which creates tension with privacy objectives. The goal of this workshop is to move toward a more comprehensive notion of Trustworthy NLP, by bringing together researchers working on those distinct yet related topics, as well as their intersection.",
      "location": "Pier 4",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://trustnlpworkshop.github.io/",
      "chair": "Yada Pruksachatkun, Ninareh Mehrabi, Kai-Wei Chang, Aram Galystan, Jwala Dhamala, Anaelia Ovalle, Apurv Verma, Yang Trista Cao, Anoop Kumar, Rahul Gupta"
    },
    {
      "id": "workshop_16",
      "title": "W16 - The 13th Workshop on Computational Approaches to Subjectivity, Sentiment \\& Social Media Analysis (WASSA)",
      "desc": "Subjectivity and Sentiment Analysis has become a highly developed research area, ranging from binary classification of reviews to the detection of complex emotion structures between entities found in text. This field has expanded both on a practical level, finding numerous successful applications in business, as well as on a theoretical level, allowing researchers to explore more complex research questions related to affective computing. Its continuing importance is also shown by the interest it generates in other disciplines such as Economics, Sociology, Psychology, Marketing, Crisis Management \\& Digital Humanities. \\\\newline The aim of WASSA 2023 is to bring together researchers working on Subjectivity, Sentiment Analysis, Emotion Detection and Classification and their applications to other NLP or real-world tasks (e.g. public health messaging, fake news, media impact analysis, social media mining, computational literary studies) and researchers working on interdisciplinary aspects of affect computation from text.",
      "location": "Hourbour C",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://wassa-workshop.github.io/",
      "chair": "Jeremy Barnes, Orph\u00e9e De Clercq, Roman Klinger, Valentin Barriere, Salvatore Giorgi, Joa\u00f5 Sedoc, Shabnam Tafreshi, Iqra Ameer, Necva B\u00f6l\u00fcc\u00fc, Hua Xu, Ali Al Bataineh"
    },
    {
      "id": "workshop_17",
      "title": "W17 - The 5th Clinical Natural Language Processing Workshop (Clinical NLP)",
      "desc": "Clinical text is growing rapidly as electronic health records become pervasive. Much of the information recorded in a clinical encounter is located exclusively in provider narrative notes, which makes them indispensable for supplementing structured clinical data in order to better understand patient state and care provided. The methods and tools developed for the clinical domain have historically lagged behind the scientific advances in the general-domain NLP. Despite the substantial recent strides in clinical NLP, a substantial gap remains. The goal of this workshop is to address this gap by establishing a regular event in CL conferences that brings together researchers interested in developing state-of-the-art methods for the clinical domain. The focus is on improving NLP technology to enable clinical applications, and specifically, information extraction and modeling of narrative provider notes from electronic health records, patient encounter transcripts, and other clinical narratives.",
      "location": "Pier 7 and 8",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://clinical-nlp.github.io/2023/",
      "chair": "Asma Ben Abacha, Steven Bethard, Tristan Naumann, Kirk Roberts, Anna Rumshisky"
    },
    {
      "id": "workshop_18",
      "title": "W18 - The 1st Workshop on Social Influence in Conversations (SICon)",
      "desc": "Social influence is the change in an individual's thoughts, feelings, attitudes, or behaviors that results from interaction with another individual or a group. For example, a buyer uses social influence skills to engage in trade-offs and build rapport when bargaining with a seller. A therapist uses social influence skills like persuasion to motivate a patient towards physical exercise. Social influence is a core function of human communication, and such scenarios are ubiquitous in everyday life, from negotiations to argumentation to behavioral interventions. Consequently, realistic human-machine conversations must reflect these social influence dynamics, making it essential to systematically model and understand them in dialogue research. This requires perspectives not only from NLP and AI research but also from game theory, emotion, communication, and psychology. \\\\newline We are excited to host the First Workshop on Social Influence in Conversations (SICon 2023). SICon 2023 will be a one-day hybrid event, co-located with ACL 2023. It would be the first venue that uniquely fosters a dedicated discussion on social influence within NLP while involving researchers from other disciplines such as affective computing and the social sciences. SICon 2023 features keynote talks, panel discussions, poster sessions, and lightning talks for accepted papers. We hope to bring together researchers and practitioners from a wide variety of disciplines to discuss important problems related to social influence, as well as share findings and recent advances. We encourage researchers of all stages and backgrounds to share their exciting work!",
      "location": "Harbour A",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://sites.google.com/view/sicon-2023/home",
      "chair": "Kushal Chawla, Weiyan Shi, Maximillian Chen, Liang Qiu, Yu Li, James Hale, Alexandros Papangelis, Gale Lucas, Zhou Yu"
    },
    {
      "id": "workshop_19",
      "title": "W19 - The 1st Workshop on Computation and Written Language (CAWL)",
      "desc": "Most work on NLP focuses on language in its canonical written form. This has often led researchers to ignore the differences between written and spoken language or, worse, to conflate the two. Instances of conflation are statements like \u201cChinese is a logographic language\" or \u201cPersian is a right-to-left language\", variants of which can be found frequently in the ACL anthology. These statements confuse properties of the language with properties of its writing system. Ignoring differences between written and spoken language leads, among other things, to conflating different words that are spelled the same (e.g., English bass), or treating as different, words that have multiple spellings. \\\\newline text enFurthermore, methods for dealing with written language issues (e.g., various kinds of normalization or conversion) or for recognizing text input (e.g. OCR \\& handwriting recognition or text entry methods) are often regarded as precursors to NLP rather than as fundamental parts of the enterprise, despite the fact that most NLP methods rely centrally on representations derived from text rather than (spoken) language. This general lack of consideration of writing has led to much of the research on such topics to largely appear outside of ACL venues, in conferences or journals of neighboring fields such as speech technology (e.g., text normalization) or human-computer interaction (e.g., text entry). \\\\newline We will invite submissions on the relationship between written and spoken language, the properties of written language, the ways in which writing systems encode language, and applications specifically focused on characteristics of writing systems.",
      "location": "Pier 2",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://cawl.wellformedness.com/",
      "chair": "Kyle Gorman, Brian Roark, Richard Sproat"
    },
    {
      "id": "workshop_20",
      "title": "W20 - The 3rd Workshop on NLP for Indigenous Languages of the Americas (AmericasNLP)",
      "desc": "AmericasNLP aims to (a) encourage research on NLP, computational linguistics, corpus linguistics, and speech around the globe to work on native American languages; (b) )connect researchers and professionals from underrepresented communities and native speakers of endangered languages with the machine learning and natural language processing communities; and (c) )promote research on both neural and non-neural machine learning approaches suitable for low-resource languages.",
      "location": "Pier 3",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://turing.iimas.unam.mx/americasnlp/",
      "chair": "Manuel Mager, Arturo Oncevay, Enora Rice, Abteen Ebrahimi, Shruti Rijhwani, Alexis Palmer, Katharina Kann"
    },
    {
      "id": "workshop_21",
      "title": "W21 - The 5th Workshop on Narrative Understanding (WNU)",
      "desc": "This is the 5th iteration of the Narrative Understanding Workshop, which brings together an interdisciplinary group of researchers from AI, ML, NLP, Computer Vision and other related fields, as well as scholars from the humanities to discuss methods to improve automatic narrative understanding capabilities. The workshop will consist of talks from invited speakers, a panel of researchers and writers, and talks and posters from accepted papers.",
      "location": "Dockside 2",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://sites.google.com/umass.edu/wnu2023",
      "chair": "Nader Akoury, Faeze Brahman, Khyathi Chandu, Snigdha Chaturvedi, Elizabeth Clark, Mohit Iyyer"
    },
    {
      "id": "workshop_22",
      "title": "W22 - The 20th Workshop on Computational Morphology and Phonology (SIGMORPHON)",
      "desc": "SIGMORPHON aims to bring together researchers interested in applying computational techniques to problems in morphology, phonology, and phonetics. Work that addresses orthographic issues is also welcome. Papers will be on substantial, original, and unpublished research on these topics, potentially including strong work in progress.",
      "location": "Dockside 3",
      "start_time": "2023-07-14T09:00:00",
      "end_time": null,
      "url": "https://sigmorphon.github.io/workshops/2023/",
      "chair": "Garrett Nicolai, Eleanor Chodroff, \u00c7a\u011fr\u0131 \u00c7\u00f6ltekin, Fred Mailhot"
    }
  ],
  "social_events": [
    {
      "title": "Welcome Reception",
      "id": "welcome-reception",
      "day": "Sunday, July 9, 2023",
      "venue": "Westin Harbour Castle Hotel",
      "start_time": "2023-07-09T19:00:00",
      "end_time": "2023-07-09T21:30:00",
      "desc": "One entry ticket will be included with each full conference registration. To get admission into the event you will need to have your name badge on your person as the QR code that is located on your badge is how the ACL Staff member(s) Scan and account for admission(s). No name badge, no entrance.",
      "location": "Westin Harbour Castle Hotel: Harbour Ballroom"
    },
    {
      "title": "Social Event",
      "id": "social-event",
      "day": "Tuesday, July 11, 2023",
      "venue": "Steam Whistle Brewing Company",
      "start_time": "2023-07-11T18:30:00",
      "end_time": "2023-07-11T22:00:00",
      "desc": "One entry ticket will be included with each full conference registration. To get admission into the event you will need to have your name badge on your person as the QR code that is located on your badge is how the ACL Staff member(s) Scan and account for admission(s). No name badge, no entrance.",
      "location": "Steam Whistle Brewing Company: Steam Whistle Brewing Company located at The Roundhouse, 255 Bremner Blvd, Toronto ON M5V 3M9"
    }
  ]
}
